{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63566e81",
   "metadata": {},
   "source": [
    "# NLP INTRODUCTION PART: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857a63a",
   "metadata": {},
   "source": [
    "## En este punto continuaremos con un ejemplo de aplicación del Método TF-IDF que se explicó en el punto pasado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d402db",
   "metadata": {},
   "source": [
    "Se usará el siguiente [dataset](https://www.kaggle.com/datasets/carolzhangdc/imdb-5000-movie-dataset) para la siguiente practica en donde se hará un recomendador de peliculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86e6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
       "3                 27000.0  448130642.0                  Action|Thriller  ...   \n",
       "4                   131.0          NaN                      Documentary  ...   \n",
       "\n",
       "  num_user_for_reviews language  country  content_rating       budget  \\\n",
       "0               3054.0  English      USA           PG-13  237000000.0   \n",
       "1               1238.0  English      USA           PG-13  300000000.0   \n",
       "2                994.0  English       UK           PG-13  245000000.0   \n",
       "3               2701.0  English      USA           PG-13  250000000.0   \n",
       "4                  NaN      NaN      NaN             NaN          NaN   \n",
       "\n",
       "   title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
       "0      2009.0                  936.0        7.9          1.78   \n",
       "1      2007.0                 5000.0        7.1          2.35   \n",
       "2      2015.0                  393.0        6.8          2.35   \n",
       "3      2012.0                23000.0        8.5          2.35   \n",
       "4         NaN                   12.0        7.1           NaN   \n",
       "\n",
       "  movie_facebook_likes  \n",
       "0                33000  \n",
       "1                    0  \n",
       "2                85000  \n",
       "3               164000  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos pandas y leemos el csv\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('movie_metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fdd018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5043 entries, 0 to 5042\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   color                      5024 non-null   object \n",
      " 1   director_name              4939 non-null   object \n",
      " 2   num_critic_for_reviews     4993 non-null   float64\n",
      " 3   duration                   5028 non-null   float64\n",
      " 4   director_facebook_likes    4939 non-null   float64\n",
      " 5   actor_3_facebook_likes     5020 non-null   float64\n",
      " 6   actor_2_name               5030 non-null   object \n",
      " 7   actor_1_facebook_likes     5036 non-null   float64\n",
      " 8   gross                      4159 non-null   float64\n",
      " 9   genres                     5043 non-null   object \n",
      " 10  actor_1_name               5036 non-null   object \n",
      " 11  movie_title                5043 non-null   object \n",
      " 12  num_voted_users            5043 non-null   int64  \n",
      " 13  cast_total_facebook_likes  5043 non-null   int64  \n",
      " 14  actor_3_name               5020 non-null   object \n",
      " 15  facenumber_in_poster       5030 non-null   float64\n",
      " 16  plot_keywords              4890 non-null   object \n",
      " 17  movie_imdb_link            5043 non-null   object \n",
      " 18  num_user_for_reviews       5022 non-null   float64\n",
      " 19  language                   5029 non-null   object \n",
      " 20  country                    5038 non-null   object \n",
      " 21  content_rating             4740 non-null   object \n",
      " 22  budget                     4551 non-null   float64\n",
      " 23  title_year                 4935 non-null   float64\n",
      " 24  actor_2_facebook_likes     5030 non-null   float64\n",
      " 25  imdb_score                 5043 non-null   float64\n",
      " 26  aspect_ratio               4714 non-null   float64\n",
      " 27  movie_facebook_likes       5043 non-null   int64  \n",
      "dtypes: float64(13), int64(3), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df['genres'] = df['genres'].str.replace('|', ' ')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaea1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action Adventure Fantasy Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action Adventure Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action Adventure Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
       "0                  1000.0  760505847.0  Action Adventure Fantasy Sci-Fi  ...   \n",
       "1                 40000.0  309404152.0         Action Adventure Fantasy  ...   \n",
       "2                 11000.0  200074175.0        Action Adventure Thriller  ...   \n",
       "3                 27000.0  448130642.0                  Action Thriller  ...   \n",
       "4                   131.0          NaN                      Documentary  ...   \n",
       "\n",
       "  num_user_for_reviews language  country  content_rating       budget  \\\n",
       "0               3054.0  English      USA           PG-13  237000000.0   \n",
       "1               1238.0  English      USA           PG-13  300000000.0   \n",
       "2                994.0  English       UK           PG-13  245000000.0   \n",
       "3               2701.0  English      USA           PG-13  250000000.0   \n",
       "4                  NaN      NaN      NaN             NaN          NaN   \n",
       "\n",
       "   title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
       "0      2009.0                  936.0        7.9          1.78   \n",
       "1      2007.0                 5000.0        7.1          2.35   \n",
       "2      2015.0                  393.0        6.8          2.35   \n",
       "3      2012.0                23000.0        8.5          2.35   \n",
       "4         NaN                   12.0        7.1           NaN   \n",
       "\n",
       "  movie_facebook_likes  \n",
       "0                33000  \n",
       "1                    0  \n",
       "2                85000  \n",
       "3               164000  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['plot_keywords'] = df['plot_keywords'].str.replace('|', ' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d63962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5043 entries, 0 to 5042\n",
      "Data columns (total 29 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   color                      5024 non-null   object \n",
      " 1   director_name              4939 non-null   object \n",
      " 2   num_critic_for_reviews     4993 non-null   float64\n",
      " 3   duration                   5028 non-null   float64\n",
      " 4   director_facebook_likes    4939 non-null   float64\n",
      " 5   actor_3_facebook_likes     5020 non-null   float64\n",
      " 6   actor_2_name               5030 non-null   object \n",
      " 7   actor_1_facebook_likes     5036 non-null   float64\n",
      " 8   gross                      4159 non-null   float64\n",
      " 9   genres                     5043 non-null   object \n",
      " 10  actor_1_name               5036 non-null   object \n",
      " 11  movie_title                5043 non-null   object \n",
      " 12  num_voted_users            5043 non-null   int64  \n",
      " 13  cast_total_facebook_likes  5043 non-null   int64  \n",
      " 14  actor_3_name               5020 non-null   object \n",
      " 15  facenumber_in_poster       5030 non-null   float64\n",
      " 16  plot_keywords              4890 non-null   object \n",
      " 17  movie_imdb_link            5043 non-null   object \n",
      " 18  num_user_for_reviews       5022 non-null   float64\n",
      " 19  language                   5029 non-null   object \n",
      " 20  country                    5038 non-null   object \n",
      " 21  content_rating             4740 non-null   object \n",
      " 22  budget                     4551 non-null   float64\n",
      " 23  title_year                 4935 non-null   float64\n",
      " 24  actor_2_facebook_likes     5030 non-null   float64\n",
      " 25  imdb_score                 5043 non-null   float64\n",
      " 26  aspect_ratio               4714 non-null   float64\n",
      " 27  movie_facebook_likes       5043 non-null   int64  \n",
      " 28  texto                      5043 non-null   object \n",
      "dtypes: float64(13), int64(3), object(13)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df['texto'] = df[['genres', 'plot_keywords']].apply(lambda row: ' '.join(row.values.astype(str)),axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d013643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres                             Action Adventure Fantasy Sci-Fi\n",
      "plot_keywords               avatar future marine native paraplegic\n",
      "texto            Action Adventure Fantasy Sci-Fi avatar future ...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row = df[['genres','plot_keywords','texto']].iloc[0]\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fabcd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos las librerias que ocuparemos.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615274bd",
   "metadata": {},
   "source": [
    "Nota: En el siguiente punto se colocaron 2000 en la variable max_features, esto se refiere al maximo que nosotros le estamos poniendo a la función más es muy probable que si quiera alcance los 2000 ya que recordemos que los tokens son palabras o caracteres unicos en los textos por lo que se llegan a ignorar los que se repiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0251f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24588b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 43997 stored elements and shape (5043, 2000)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(df['texto'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96703c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_title\n",
       "Avatar                                        0\n",
       "Pirates of the Caribbean: At World's End      1\n",
       "Spectre                                       2\n",
       "The Dark Knight Rises                         3\n",
       "Star Wars: Episode VII - The Force Awakens    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapeo de peliculas y limpieza\n",
    "peliculas = pd.Series(df.index, index=df['movie_title'])\n",
    "peliculas.index = peliculas.index.str.strip()\n",
    "peliculas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f9b147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "indice = peliculas['Avatar']\n",
    "print(indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56432c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 8 stored elements and shape (1, 2000)>\n",
      "  Coords\tValues\n",
      "  (0, 34)\t0.18454616338200297\n",
      "  (0, 44)\t0.20147225203094668\n",
      "  (0, 636)\t0.23175872595803823\n",
      "  (0, 1554)\t0.23163756512772668\n",
      "  (0, 653)\t0.23163756512772668\n",
      "  (0, 718)\t0.4164065793214277\n",
      "  (0, 1071)\t0.5199567176285965\n",
      "  (0, 1176)\t0.566196244705834\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "consulta = X[indice]\n",
    "print(consulta)\n",
    "print(consulta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6a2d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.10112454 0.06949699 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similitud = cosine_similarity(consulta, X)\n",
    "print(similitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287772ab",
   "metadata": {},
   "source": [
    "¿Qué significa esa salida? R: Esa matriz es la similitud que tiene la pelicula con los de la lista de titulos, por ejemplo, nosotros elegimos la pelicula \"Avatar\", y como se ve en el array el primer valor es un \"1\", eso quiere decir que dicha pelicula tiene mucha similitud con \"Avatar\" (claro porque es la misma). Veamos más ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d8693f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similitud = similitud.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673f4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.02767797617392109)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similitud[3] #Avatar y The Dark Knight Rises  tienen una similitud del 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b9891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similitud[4] #Avatar y Star Wars: Episode VII - The Force Awakens tienen una similitud del 0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adb3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10112453992495118)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similitud[1] #Avatar y Pirates of the Caribbean: At World's End  tienen una similitud del 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda6b46",
   "metadata": {},
   "source": [
    "Para ver de una forma más visual estas similitudes vamos a graficarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7704466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "371a2667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1933ffdccd0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(similitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42212cb",
   "metadata": {},
   "source": [
    "Como se puede observar en la grafica, vemos que el primero de la lista tiene una similitud del 100%, esto por ser la misma pelicula pero podemos encontrar muchas peliculas que sobrepasan la similitud del 40%. Pero, ¿Cuales peliculas son las más similares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f17e2115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 3324,  601, ..., 5013, 5011,   26], shape=(5043,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-similitud).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0492dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324    Ultramarines: A Warhammer 40,000 Movie \n",
       "601                         Battle Los Angeles \n",
       "76                                  Waterworld \n",
       "1334                                  Serenity \n",
       "4264                             Smoke Signals \n",
       "1314                                  Sunshine \n",
       "4697                          Naturally Native \n",
       "373               A.I. Artificial Intelligence \n",
       "1563                                  Repo Men \n",
       "4467       Space: Above and Beyond             \n",
       "Name: movie_title, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion = (-similitud).argsort()[1:11]\n",
    "df['movie_title'].iloc[recomendacion]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42003431",
   "metadata": {},
   "source": [
    "Si ustedes quieren probar con otra pelicula simplemente regresen al Code Cell #15, cambian el nombre de la pelicula y vuelven a ejecutar todas las demás celdas por debajo de la 15 hasta la 45."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee34f8b",
   "metadata": {},
   "source": [
    "## Neuronal Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17c2b1",
   "metadata": {},
   "source": [
    "¿Recuerdan el post anterior donde se hablabá de similitud de vectores donde las palabras se convertian en vectores?\n",
    "Bueno aquí es cuando tocamos más a fondo el tema.\n",
    "Aquí es donde cada cadena se convierte en un vector. Por ejemplo:\n",
    "```sql\n",
    "palabras = {'gato':[0.1,0.9],\n",
    "            'perro':[0.15,0.85]}\n",
    "```\n",
    "\n",
    "Recordemos que la vectorización de palabras es para poder medir la distancia entre una palabra y otras para que el modelo pueda comprender mejor las relaciones.\n",
    "\n",
    "En el ejemplo dado podemos observar que tal cual 'gato' y 'perro' no son iguales pero estan muy cercas, quizás por la relación \"mascota\", \"mamifero\",etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad333011",
   "metadata": {},
   "source": [
    "### Métodos de vectorización\n",
    "\n",
    "- Conversión de documentos en vectores (\"Bolsa de palabras\", \"TF-IDF\")\n",
    "- Palabras a vectores\n",
    "- Embeddings (Descripción de la representación de documentos similares mediante una secuencia de vectores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df117e",
   "metadata": {},
   "source": [
    "### Modelos de secuencias en aprendizaje profundo\n",
    "\n",
    "- Modelos construidos para secuencias \n",
    "    - CNN: Usualmente usada en vision computarizada (Detección y clasificación de imagenes), o clasificación de texto.\n",
    "    - RNN: Muy usado en el traducción de idiomás donde tiene mucho peso el orden de las palabras en una sentencia.\n",
    "    - Transformers: Usado por GPT4, BERT; Este mantiene el contexto global del texto.\n",
    "- Relevancia del orden de las palabras en una sentencia.\n",
    "- Aplicación en traducciones de idiomas, respuestas a preguntas, chatbots, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268818bf",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "El word embedding convierte una palabra en un vector, ¿Esto que nos permite hacer/lograr? Al convertir o representar las palabras en vectores nos permitirá no solo capturar la relación entre las mismas, sino que tambien su significado o contexto.\n",
    "\n",
    "Las tecnicas más populares para lograr esto son:\n",
    "- Word2Vec: Usa redes neuronales usando CBOW y Skip-Gram.\n",
    "- GloVe: Diseñado para capturar la información semantica y sintactica de la palabra basandose en la \"matriz de concurrencia de la palabra\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7906cec",
   "metadata": {},
   "source": [
    "### Problematica que soluciona Word Embeddings\n",
    "\n",
    "Imaginemos que tenemos las siguientes palabras:\n",
    "- Alemania\n",
    "- España\n",
    "- Madrid\n",
    "- Berlín\n",
    "\n",
    "Mientras que otros métodos de vectorización, como Bag of Words o TF-IDF, solo indican la frecuencia o importancia de una palabra dentro de un conjunto de documentos, los word embeddings son capaces de capturar relaciones semánticas y analogías entre palabras mediante incrustaciones en un espacio vectorial.\n",
    "\n",
    "Por ejemplo, supongamos que obtenemos los siguientes vectores:\n",
    "\n",
    "```python\n",
    "palabras = {\n",
    "    'Alemania':[0.5, 1.0],\n",
    "    'España':[0.5, 0.5],\n",
    "    'Madrid':[1.0, 1.0],\n",
    "    'Berlín':[1.0, 1.5]\n",
    "}\n",
    "```\n",
    "Podemos observar que Alemania y España están cerca entre sí, al igual que Madrid y Berlín. Esto sugiere que el modelo ha aprendido que Alemania y España son países, y que Madrid y Berlín son ciudades.\n",
    "\n",
    "Además, los embeddings pueden capturar relaciones más profundas, como:\n",
    "\n",
    "- Berlín - Alemania + España ≈ Madrid\n",
    "\n",
    "Es decir, el modelo entiende que la relación entre país y su capital se mantiene de forma similar en el espacio vectorial.\n",
    "\n",
    "Esa capacidad de representar similitudes y analogías entre palabras es lo que hace tan potentes a los word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f1456",
   "metadata": {},
   "source": [
    "## Parte practica de Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adf58b",
   "metadata": {},
   "source": [
    "### Similitud\n",
    "\n",
    "El punto de esta practica es crear una función en el cual se manden 3 palabras (Rey, Hombre, Mujer) y el modelo debe de predecir la 4 palabra que debe ser Reina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e40213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalación de librerias necesarias\n",
    "%pip install gensim -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos la libreria\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd069397",
   "metadata": {},
   "source": [
    "Para esta parte se usará el siguiente [dataset](https://www.kaggle.com/datasets/rtatman/pretrained-word-vectors-for-spanish) (por cuestiones de almacenamiento en git, este documento no se agregará al repositorio pero podran descargarlo por ustedes mismos desde el link.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84939d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectores = gensim.models.KeyedVectors.load_word2vec_format('SBW-vectors-300-min5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23089951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explicación\n",
    "'''\n",
    "Cómo se mencionó anteriormente, el modelo debe de predecir la cuarta palabra. Aqui tenemos 2 variables:\n",
    "- Positive\n",
    "- Negative\n",
    "El polo positivo, la relación que se tiene con el negativo es que el v1 = v2 (Rey es Hombre), v3 es Mujer, por\n",
    "lo que queremos es que encuentre la palabra Reina.\n",
    "'''\n",
    "def analogia(v1,v2,v3):\n",
    "    similitud = vectores.most_similar(positive=[v1,v3],negative=[v2])\n",
    "    print(f\"{v1} es a {v2}, como {similitud[0][0]} es a {v3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62b1d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rey es a hombre, como reina es a mujer\n"
     ]
    }
   ],
   "source": [
    "analogia('rey','hombre','mujer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ab62b",
   "metadata": {},
   "source": [
    "Cómo se puede observar, el modelo logró predecir la palabra. Ahora hagamos más pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c46b3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pan es a trigo, como yogur es a leche\n"
     ]
    }
   ],
   "source": [
    "analogia('pan','trigo','leche')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb2715e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alemania es a alemán, como España es a español\n"
     ]
    }
   ],
   "source": [
    "analogia('alemania','alemán','español')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92f0442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platano es a potasio, como yautía es a zinc\n"
     ]
    }
   ],
   "source": [
    "#uno más dificil\n",
    "analogia('platano','potasio','zinc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c9777",
   "metadata": {},
   "source": [
    "Nota: Al realizar algunos experimientos con ciertas analogias (ejemplo: 'México','Guatemala','Canadá') donde me arroja resultados erroneos. Esto puede ser por como es que se entrenó el modelo, pero por si acaso veamos las palabras cercanas de ciertas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1a5f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cercanos(v):\n",
    "    vecinos = vectores.most_similar(positive=[v])\n",
    "    print(\"vecinos de la palabra: %s\" % v)\n",
    "    for word, score in vecinos:\n",
    "        print(\"\\t%s\" % word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf0a51b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecinos de la palabra: Canadá\n",
      "\tQuebec\n",
      "\tAustralia\n",
      "\tOntario\n",
      "\tEstados\n",
      "\tcanadienses\n",
      "\tCalgary\n",
      "\tUnido\n",
      "\tUnidos\n",
      "\tCánada\n",
      "\tAlberta\n"
     ]
    }
   ],
   "source": [
    "cercanos('Canadá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd7f54e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecinos de la palabra: México\n",
      "\tCiudad\n",
      "\tmexicana\n",
      "\tToluca\n",
      "\tQuerétaro\n",
      "\tmexicano\n",
      "\tmexicanos\n",
      "\tVeracruz\n",
      "\tOaxaca\n",
      "\tGuanajuato\n",
      "\tChiapas\n"
     ]
    }
   ],
   "source": [
    "cercanos('México')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1655a524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecinos de la palabra: taco\n",
      "\ttacos\n",
      "\tespiche\n",
      "\tpalillo\n",
      "\ttaquito\n",
      "\tcachetear\n",
      "\tplacero\n",
      "\tpalo\n",
      "\tvirote\n",
      "\tpicadita\n",
      "\tcapellada\n"
     ]
    }
   ],
   "source": [
    "cercanos('taco')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fdc10",
   "metadata": {},
   "source": [
    "### Nuestro propio Embedding con Word2Vec\n",
    "\n",
    "Recordemos un poco lo que es Word2Vec.\n",
    "\n",
    "Word2Vec es un modelo que se utiliza para aprender representaciones vectoriales de palabras. Estas representaciones\n",
    "pueden capturar muchas propiedades lingüisticas de las palabras, como su significado semantico, gramatical y contextual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalación de librerias\n",
    "%pip install pymupdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f39c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importación de librerias\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3230414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar el documento\n",
    "with open('texto_test.txt', 'r', encoding='utf-8') as file:\n",
    "    documento = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#en caso de que sea un pdf será así\n",
    "def extraer_texto_pdf(ruta_archivo):\n",
    "    doc = pymupdf.open(ruta_archivo)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text \n",
    "\n",
    "documento = extraer_texto_pdf('Models.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e4abf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alan Turing\\n(Alan Mathison Turing; Londres, 1912 - Wilmslow, Reino Unido, 1954) Matemático británico. Pasó sus primeros trece años en la India, donde su padre trabajaba en la Administración colonial. De regreso al Reino Unido, estudió en el King\\'s College y, tras su graduación, se trasladó a la Universidad estadounidense de Princeton, donde trabajó con el lógico Alonzo Church.\\nEn 1937 publicó un célebre artículo en el que definió una máquina calculadora de capacidad infinita (máquina de Turing) que operaba basándose en una serie de instrucciones lógicas, sentando así las bases del concepto moderno de algoritmo. Turing describió en términos matemáticos precisos cómo un sistema automático con reglas extremadamente simples podía efectuar toda clase de operaciones matemáticas expresadas en un lenguaje formal determinado. La máquina de Turing era tanto un ejemplo de su teoría de computación como una prueba de que un cierto tipo de máquina computadora podía ser construida.\\n\\nLa Segunda Guerra Mundial ofreció un insospechado marco de aplicación práctica de sus teorías, al surgir la necesidad de descifrar los mensajes codificados que la Marina alemana empleaba para enviar instrucciones a los submarinos que hostigaban los convoyes de ayuda material enviados desde Estados Unidos; Turing, al mando de una división de la Inteligencia británica, diseñó tanto los procesos como las máquinas que, capaces de efectuar cálculos combinatorios mucho más rápidamente que cualquier ser humano, fueron decisivos en la ruptura final del código.\\n\\nAlan Turing definió además un método teórico para decidir si una máquina era capaz de pensar como un hombre (test de Turing) y realizó contribuciones a otras ramas de la matemática aplicada, como la aplicación de métodos analíticos y mecánicos al problema biológico de la morfogénesis. En el ámbito personal, su condición de homosexual fue motivo constante de fuertes presiones sociales y familiares, hasta el punto de especularse si su muerte por intoxicación fue accidental o se debió a un intento de suicidio.\\n\\n¿Qué es el Test de Turing en IA?\\nEl Test de Turing es un método de investigación en inteligencia artificial (IA) para determinar si un ordenador es capaz o no de pensar como un ser humano. La prueba lleva el nombre de Alan Turing, el fundador de la prueba de Turing y un informático, criptoanalista, matemático y biólogo teórico inglés.\\n\\nTuring propuso que se puede decir que una computadora posee inteligencia artificial si puede imitar las respuestas humanas en condiciones específicas. La prueba de Turing original requiere tres terminales, cada uno de los cuales está físicamente separado de los otros dos. Un terminal es operado por una computadora, mientras que los otros dos son operados por humanos.\\n\\nDurante la prueba, uno de los humanos funciona como interrogador, mientras que el segundo humano y la computadora funcionan como encuestados. El interrogador interroga a los encuestados dentro de un área temática específica, utilizando un formato y contexto específicos. Después de un período de tiempo preestablecido o un número de preguntas, se le pide al interrogador que decida qué encuestado era humano y cuál era una computadora.\\n\\nLa prueba se repite muchas veces. Si el interrogador toma la determinación correcta en la mitad de las ejecuciones de prueba o menos, se considera que la computadora tiene inteligencia artificial porque el interrogador la considera \"tan humana\" como el encuestado humano.\\n\\nHistoria de la prueba de Turing\\nLa prueba lleva el nombre de Alan Turing, quien fue pionero en el aprendizaje automático durante las décadas de 1940 y 1950. Turing introdujo la prueba en su artículo de 1950 llamado \"Computing Machinery and Intelligence\" mientras estaba en la Universidad de Manchester.\\n\\nEn su artículo, Turing propuso un giro en lo que se llama \"El juego de la imitación\". El juego de imitación no implica el uso de IA, sino tres participantes humanos en tres habitaciones separadas. Cada sala está conectada a través de una pantalla y un teclado, uno con un hombre, el otro con una mujer y el otro con un juez masculino o femenino. La mujer trata de convencer al juez de que ella es el hombre, y el juez trata de difundir cuál es cuál.\\n\\nTuring cambia el concepto de este juego para incluir una IA, un humano y un interrogador humano. El trabajo del interrogador es decidir cuál es la IA y cuál es el humano. Desde la formación de la prueba, muchas IA han podido pasar; uno de los primeros es un programa creado por Joseph Weizenbaum llamado ELIZA.\\n\\nLimitaciones de la prueba de Turing\\nLa prueba de Turing ha sido criticada a lo largo de los años, en particular porque históricamente, la naturaleza del interrogatorio tenía que ser limitada para que una computadora exhibiera una inteligencia similar a la humana. Durante muchos años, una computadora solo podía obtener una puntuación alta si el interrogador formulaba las consultas, por lo que tenían respuestas de \"Sí\" o \"No\" o pertenecían a un campo estrecho de conocimiento. Cuando las preguntas eran abiertas y requerían respuestas conversacionales, era menos probable que el programa de computadora pudiera engañar con éxito al interrogador.\\n\\nAdemás, un programa como ELIZA podría pasar la prueba de Turing manipulando símbolos que no comprende completamente. John Searle argumentó que esto no determina una inteligencia comparable a la de los humanos.\\n\\nPara muchos investigadores, la cuestión de si una computadora puede o no pasar una prueba de Turing se ha vuelto irrelevante. En lugar de centrarse en cómo convencer a alguien de que está conversando con un humano y no con un programa informático, el enfoque real debería estar en cómo hacer que una interacción humano-máquina sea más intuitiva y eficiente. Por ejemplo, mediante el uso de una interfaz conversacional.\\n\\nVariaciones y alternativas al Test de Turing\\nHa habido una serie de variaciones en la prueba de Turing para hacerla más relevante. Tales ejemplos incluyen:\\n\\nPrueba de Turing inversa: donde un humano intenta convencer a una computadora de que no es una computadora. Un ejemplo de esto es un CAPTCHA.\\nPrueba de Turing total: donde el interrogador también puede probar las habilidades perceptivas, así como la capacidad de manipular objetos.\\nPrueba de señal inteligente mínima: donde solo se dan preguntas de verdadero / falso y sí / no.\\nMás tarde se desarrollaron alternativas a las pruebas de Turing porque muchos consideran que la prueba de Turing es defectuosa. Estas alternativas incluyen pruebas como:\\n\\nLa prueba de Marcus, en la que un programa que puede \"ver\" un programa de televisión se prueba haciéndole preguntas significativas sobre el contenido del programa.\\nLa prueba Lovelace 2.0, que es una prueba hecha para detectar IA mediante el examen de su capacidad para crear arte.\\nWinograd Schema Challenge: que es una prueba que hace preguntas de opción múltiple en un formato específico.\\n¿Cómo se usa la prueba de Turing en la actualidad?\\nAunque las variaciones de la prueba de Turing suelen ser más aplicables a nuestra comprensión actual de la IA, el formato original de la prueba todavía se usa hasta el día de hoy. Por ejemplo, el Premio Loebner se otorga anualmente desde 1990 al programa informático más parecido al humano según lo votado por un panel de jueces. La competencia sigue las reglas estándar de la prueba de Turing. Los críticos de la relevancia del premio a menudo lo minimizan como más publicidad que realmente probar si las máquinas pueden pensar.\\n\\nEn una competencia organizada por la Universidad de Reading para conmemorar el 60 aniversario de la muerte de Turing en 2014, un chatbot llamado Eugene Goostman que simula a un niño de 13 años pasó la prueba de Turing, a los ojos de algunos, cuando engañó al 33% de los jueces. Este llamado primer paso ha sido recibido con muchas críticas por parte de quienes argumentan que no hubo suficientes jueces, que otras máquinas se han desempeñado mejor en la prueba en el pasado y que la prueba no es válida por solo durar cinco minutos.\\n\\nEn 2018, Google Duplex concertó con éxito una cita con un peluquero por teléfono frente a una multitud de 7.000 personas. La recepcionista desconocía por completo que no estaban conversando con un humano real. Algunos consideran que esto es un pase de prueba de Turing moderno, a pesar de no depender del verdadero formato de la prueba tal como lo diseñó Alan Turing.\\n\\nAlgunos creen que GPT-3, un modelo de procesamiento de lenguaje natural creado por OpenAI, tiene la mejor oportunidad de superar la prueba en su forma real de cualquier tecnología que tengamos hoy. Pero, incluso con sus capacidades avanzadas de generación de texto, muchos han criticado a la máquina porque puede ser engañada para responder preguntas sin sentido y, por lo tanto, tendría dificultades en las condiciones de la prueba de Turing.\\n\\nA pesar de mucho debate sobre la relevancia de la prueba de Turing en la actualidad y la validez de las competencias que se basan en ella, la prueba sigue siendo un punto de partida filosófico para discutir e investigar la IA. A medida que continuamos avanzando en IA y comprendemos y mapeamos mejor cómo funciona el cerebro humano, la prueba de Turing sigue siendo fundamental para definir la inteligencia y es una línea de base para el debate sobre lo que debemos esperar de las tecnologías para que se consideren máquinas pensantes.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vemos el texto\n",
    "documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c66d9548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9384"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b7e5b",
   "metadata": {},
   "source": [
    "En este caso el documento tiene 9384 caracteres, si es posible hagan un documento más extenso para tener más caracteres pero por cuestiones de este ejemplo continuaremos con este."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528994f",
   "metadata": {},
   "source": [
    "El siguiente paso es **Procesamiento de datos**\n",
    "\n",
    "El objetivo es convertir el documento en una lista de frases, y cada frase en una lista de palabras, eliminando signos de puntuación y convirtiendo todo en minusculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55ed85b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividir el texto en frases usando algun signo como separador.\n",
    "oraciones = documento.split('.')\n",
    "len(oraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76f275a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alan Turing\\n(Alan Mathison Turing; Londres, 1912 - Wilmslow, Reino Unido, 1954) Matemático británico'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veamos la primera oración que nos da\n",
    "oraciones[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ce086f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alan', 'turing', 'alan', 'mathison', 'turing', 'londres', 'wilmslow', 'reino', 'unido', 'matemático', 'británico'], ['pasó', 'sus', 'primeros', 'trece', 'años', 'en', 'la', 'india', 'donde', 'su', 'padre', 'trabajaba', 'en', 'la', 'administración', 'colonial'], ['de', 'regreso', 'al', 'reino', 'unido', 'estudió', 'en', 'el', 'kings', 'college', 'y', 'tras', 'su', 'graduación', 'se', 'trasladó', 'a', 'la', 'universidad', 'estadounidense', 'de', 'princeton', 'donde', 'trabajó', 'con', 'el', 'lógico', 'alonzo', 'church'], ['en', 'publicó', 'un', 'célebre', 'artículo', 'en', 'el', 'que', 'definió', 'una', 'máquina', 'calculadora', 'de', 'capacidad', 'infinita', 'máquina', 'de', 'turing', 'que', 'operaba', 'basándose', 'en', 'una', 'serie', 'de', 'instrucciones', 'lógicas', 'sentando', 'así', 'las', 'bases', 'del', 'concepto', 'moderno', 'de', 'algoritmo'], ['turing', 'describió', 'en', 'términos', 'matemáticos', 'precisos', 'cómo', 'un', 'sistema', 'automático', 'con', 'reglas', 'extremadamente', 'simples', 'podía', 'efectuar', 'toda', 'clase', 'de', 'operaciones', 'matemáticas', 'expresadas', 'en', 'un', 'lenguaje', 'formal', 'determinado'], ['la', 'máquina', 'de', 'turing', 'era', 'tanto', 'un', 'ejemplo', 'de', 'su', 'teoría', 'de', 'computación', 'como', 'una', 'prueba', 'de', 'que', 'un', 'cierto', 'tipo', 'de', 'máquina', 'computadora', 'podía', 'ser', 'construida'], ['la', 'segunda', 'guerra', 'mundial', 'ofreció', 'un', 'insospechado', 'marco', 'de', 'aplicación', 'práctica', 'de', 'sus', 'teorías', 'al', 'surgir', 'la', 'necesidad', 'de', 'descifrar', 'los', 'mensajes', 'codificados', 'que', 'la', 'marina', 'alemana', 'empleaba', 'para', 'enviar', 'instrucciones', 'a', 'los', 'submarinos', 'que', 'hostigaban', 'los', 'convoyes', 'de', 'ayuda', 'material', 'enviados', 'desde', 'estados', 'unidos', 'turing', 'al', 'mando', 'de', 'una', 'división', 'de', 'la', 'inteligencia', 'británica', 'diseñó', 'tanto', 'los', 'procesos', 'como', 'las', 'máquinas', 'que', 'capaces', 'de', 'efectuar', 'cálculos', 'combinatorios', 'mucho', 'más', 'rápidamente', 'que', 'cualquier', 'ser', 'humano', 'fueron', 'decisivos', 'en', 'la', 'ruptura', 'final', 'del', 'código'], ['alan', 'turing', 'definió', 'además', 'un', 'método', 'teórico', 'para', 'decidir', 'si', 'una', 'máquina', 'era', 'capaz', 'de', 'pensar', 'como', 'un', 'hombre', 'test', 'de', 'turing', 'y', 'realizó', 'contribuciones', 'a', 'otras', 'ramas', 'de', 'la', 'matemática', 'aplicada', 'como', 'la', 'aplicación', 'de', 'métodos', 'analíticos', 'y', 'mecánicos', 'al', 'problema', 'biológico', 'de', 'la', 'morfogénesis'], ['en', 'el', 'ámbito', 'personal', 'su', 'condición', 'de', 'homosexual', 'fue', 'motivo', 'constante', 'de', 'fuertes', 'presiones', 'sociales', 'y', 'familiares', 'hasta', 'el', 'punto', 'de', 'especularse', 'si', 'su', 'muerte', 'por', 'intoxicación', 'fue', 'accidental', 'o', 'se', 'debió', 'a', 'un', 'intento', 'de', 'suicidio'], ['es', 'el', 'test', 'de', 'turing', 'en', 'ia', 'el', 'test', 'de', 'turing', 'es', 'un', 'método', 'de', 'investigación', 'en', 'inteligencia', 'artificial', 'ia', 'para', 'determinar', 'si', 'un', 'ordenador', 'es', 'capaz', 'o', 'no', 'de', 'pensar', 'como', 'un', 'ser', 'humano'], ['la', 'prueba', 'lleva', 'el', 'nombre', 'de', 'alan', 'turing', 'el', 'fundador', 'de', 'la', 'prueba', 'de', 'turing', 'y', 'un', 'informático', 'criptoanalista', 'matemático', 'y', 'biólogo', 'teórico', 'inglés'], ['turing', 'propuso', 'que', 'se', 'puede', 'decir', 'que', 'una', 'computadora', 'posee', 'inteligencia', 'artificial', 'si', 'puede', 'imitar', 'las', 'respuestas', 'humanas', 'en', 'condiciones', 'específicas'], ['la', 'prueba', 'de', 'turing', 'original', 'requiere', 'tres', 'terminales', 'cada', 'uno', 'de', 'los', 'cuales', 'está', 'físicamente', 'separado', 'de', 'los', 'otros', 'dos'], ['un', 'terminal', 'es', 'operado', 'por', 'una', 'computadora', 'mientras', 'que', 'los', 'otros', 'dos', 'son', 'operados', 'por', 'humanos'], ['durante', 'la', 'prueba', 'uno', 'de', 'los', 'humanos', 'funciona', 'como', 'interrogador', 'mientras', 'que', 'el', 'segundo', 'humano', 'y', 'la', 'computadora', 'funcionan', 'como', 'encuestados'], ['el', 'interrogador', 'interroga', 'a', 'los', 'encuestados', 'dentro', 'de', 'un', 'área', 'temática', 'específica', 'utilizando', 'un', 'formato', 'y', 'contexto', 'específicos'], ['después', 'de', 'un', 'período', 'de', 'tiempo', 'preestablecido', 'o', 'un', 'número', 'de', 'preguntas', 'se', 'le', 'pide', 'al', 'interrogador', 'que', 'decida', 'qué', 'encuestado', 'era', 'humano', 'y', 'cuál', 'era', 'una', 'computadora'], ['la', 'prueba', 'se', 'repite', 'muchas', 'veces'], ['si', 'el', 'interrogador', 'toma', 'la', 'determinación', 'correcta', 'en', 'la', 'mitad', 'de', 'las', 'ejecuciones', 'de', 'prueba', 'o', 'menos', 'se', 'considera', 'que', 'la', 'computadora', 'tiene', 'inteligencia', 'artificial', 'porque', 'el', 'interrogador', 'la', 'considera', 'tan', 'humana', 'como', 'el', 'encuestado', 'humano'], ['historia', 'de', 'la', 'prueba', 'de', 'turing', 'la', 'prueba', 'lleva', 'el', 'nombre', 'de', 'alan', 'turing', 'quien', 'fue', 'pionero', 'en', 'el', 'aprendizaje', 'automático', 'durante', 'las', 'décadas', 'de', 'y'], ['turing', 'introdujo', 'la', 'prueba', 'en', 'su', 'artículo', 'de', 'llamado', 'computing', 'machinery', 'and', 'intelligence', 'mientras', 'estaba', 'en', 'la', 'universidad', 'de', 'manchester'], ['en', 'su', 'artículo', 'turing', 'propuso', 'un', 'giro', 'en', 'lo', 'que', 'se', 'llama', 'el', 'juego', 'de', 'la', 'imitación'], ['el', 'juego', 'de', 'imitación', 'no', 'implica', 'el', 'uso', 'de', 'ia', 'sino', 'tres', 'participantes', 'humanos', 'en', 'tres', 'habitaciones', 'separadas'], ['cada', 'sala', 'está', 'conectada', 'a', 'través', 'de', 'una', 'pantalla', 'y', 'un', 'teclado', 'uno', 'con', 'un', 'hombre', 'el', 'otro', 'con', 'una', 'mujer', 'y', 'el', 'otro', 'con', 'un', 'juez', 'masculino', 'o', 'femenino'], ['la', 'mujer', 'trata', 'de', 'convencer', 'al', 'juez', 'de', 'que', 'ella', 'es', 'el', 'hombre', 'y', 'el', 'juez', 'trata', 'de', 'difundir', 'cuál', 'es', 'cuál'], ['turing', 'cambia', 'el', 'concepto', 'de', 'este', 'juego', 'para', 'incluir', 'una', 'ia', 'un', 'humano', 'y', 'un', 'interrogador', 'humano'], ['el', 'trabajo', 'del', 'interrogador', 'es', 'decidir', 'cuál', 'es', 'la', 'ia', 'y', 'cuál', 'es', 'el', 'humano'], ['desde', 'la', 'formación', 'de', 'la', 'prueba', 'muchas', 'ia', 'han', 'podido', 'pasar', 'uno', 'de', 'los', 'primeros', 'es', 'un', 'programa', 'creado', 'por', 'joseph', 'weizenbaum', 'llamado', 'eliza'], ['limitaciones', 'de', 'la', 'prueba', 'de', 'turing', 'la', 'prueba', 'de', 'turing', 'ha', 'sido', 'criticada', 'a', 'lo', 'largo', 'de', 'los', 'años', 'en', 'particular', 'porque', 'históricamente', 'la', 'naturaleza', 'del', 'interrogatorio', 'tenía', 'que', 'ser', 'limitada', 'para', 'que', 'una', 'computadora', 'exhibiera', 'una', 'inteligencia', 'similar', 'a', 'la', 'humana'], ['durante', 'muchos', 'años', 'una', 'computadora', 'solo', 'podía', 'obtener', 'una', 'puntuación', 'alta', 'si', 'el', 'interrogador', 'formulaba', 'las', 'consultas', 'por', 'lo', 'que', 'tenían', 'respuestas', 'de', 'sí', 'o', 'no', 'o', 'pertenecían', 'a', 'un', 'campo', 'estrecho', 'de', 'conocimiento'], ['cuando', 'las', 'preguntas', 'eran', 'abiertas', 'y', 'requerían', 'respuestas', 'conversacionales', 'era', 'menos', 'probable', 'que', 'el', 'programa', 'de', 'computadora', 'pudiera', 'engañar', 'con', 'éxito', 'al', 'interrogador'], ['además', 'un', 'programa', 'como', 'eliza', 'podría', 'pasar', 'la', 'prueba', 'de', 'turing', 'manipulando', 'símbolos', 'que', 'no', 'comprende', 'completamente'], ['john', 'searle', 'argumentó', 'que', 'esto', 'no', 'determina', 'una', 'inteligencia', 'comparable', 'a', 'la', 'de', 'los', 'humanos'], ['para', 'muchos', 'investigadores', 'la', 'cuestión', 'de', 'si', 'una', 'computadora', 'puede', 'o', 'no', 'pasar', 'una', 'prueba', 'de', 'turing', 'se', 'ha', 'vuelto', 'irrelevante'], ['en', 'lugar', 'de', 'centrarse', 'en', 'cómo', 'convencer', 'a', 'alguien', 'de', 'que', 'está', 'conversando', 'con', 'un', 'humano', 'y', 'no', 'con', 'un', 'programa', 'informático', 'el', 'enfoque', 'real', 'debería', 'estar', 'en', 'cómo', 'hacer', 'que', 'una', 'interacción', 'humanomáquina', 'sea', 'más', 'intuitiva', 'y', 'eficiente'], ['por', 'ejemplo', 'mediante', 'el', 'uso', 'de', 'una', 'interfaz', 'conversacional'], ['variaciones', 'y', 'alternativas', 'al', 'test', 'de', 'turing', 'ha', 'habido', 'una', 'serie', 'de', 'variaciones', 'en', 'la', 'prueba', 'de', 'turing', 'para', 'hacerla', 'más', 'relevante'], ['tales', 'ejemplos', 'incluyen', 'prueba', 'de', 'turing', 'inversa', 'donde', 'un', 'humano', 'intenta', 'convencer', 'a', 'una', 'computadora', 'de', 'que', 'no', 'es', 'una', 'computadora'], ['un', 'ejemplo', 'de', 'esto', 'es', 'un', 'captcha'], ['prueba', 'de', 'turing', 'total', 'donde', 'el', 'interrogador', 'también', 'puede', 'probar', 'las', 'habilidades', 'perceptivas', 'así', 'como', 'la', 'capacidad', 'de', 'manipular', 'objetos'], ['prueba', 'de', 'señal', 'inteligente', 'mínima', 'donde', 'solo', 'se', 'dan', 'preguntas', 'de', 'verdadero', 'falso', 'y', 'sí', 'no'], ['más', 'tarde', 'se', 'desarrollaron', 'alternativas', 'a', 'las', 'pruebas', 'de', 'turing', 'porque', 'muchos', 'consideran', 'que', 'la', 'prueba', 'de', 'turing', 'es', 'defectuosa'], ['estas', 'alternativas', 'incluyen', 'pruebas', 'como', 'la', 'prueba', 'de', 'marcus', 'en', 'la', 'que', 'un', 'programa', 'que', 'puede', 'ver', 'un', 'programa', 'de', 'televisión', 'se', 'prueba', 'haciéndole', 'preguntas', 'significativas', 'sobre', 'el', 'contenido', 'del', 'programa'], ['la', 'prueba', 'lovelace'], ['que', 'es', 'una', 'prueba', 'hecha', 'para', 'detectar', 'ia', 'mediante', 'el', 'examen', 'de', 'su', 'capacidad', 'para', 'crear', 'arte'], ['winograd', 'schema', 'challenge', 'que', 'es', 'una', 'prueba', 'que', 'hace', 'preguntas', 'de', 'opción', 'múltiple', 'en', 'un', 'formato', 'específico'], ['se', 'usa', 'la', 'prueba', 'de', 'turing', 'en', 'la', 'actualidad', 'aunque', 'las', 'variaciones', 'de', 'la', 'prueba', 'de', 'turing', 'suelen', 'ser', 'más', 'aplicables', 'a', 'nuestra', 'comprensión', 'actual', 'de', 'la', 'ia', 'el', 'formato', 'original', 'de', 'la', 'prueba', 'todavía', 'se', 'usa', 'hasta', 'el', 'día', 'de', 'hoy'], ['por', 'ejemplo', 'el', 'premio', 'loebner', 'se', 'otorga', 'anualmente', 'desde', 'al', 'programa', 'informático', 'más', 'parecido', 'al', 'humano', 'según', 'lo', 'votado', 'por', 'un', 'panel', 'de', 'jueces'], ['la', 'competencia', 'sigue', 'las', 'reglas', 'estándar', 'de', 'la', 'prueba', 'de', 'turing'], ['los', 'críticos', 'de', 'la', 'relevancia', 'del', 'premio', 'a', 'menudo', 'lo', 'minimizan', 'como', 'más', 'publicidad', 'que', 'realmente', 'probar', 'si', 'las', 'máquinas', 'pueden', 'pensar'], ['en', 'una', 'competencia', 'organizada', 'por', 'la', 'universidad', 'de', 'reading', 'para', 'conmemorar', 'el', 'aniversario', 'de', 'la', 'muerte', 'de', 'turing', 'en', 'un', 'chatbot', 'llamado', 'eugene', 'goostman', 'que', 'simula', 'a', 'un', 'niño', 'de', 'años', 'pasó', 'la', 'prueba', 'de', 'turing', 'a', 'los', 'ojos', 'de', 'algunos', 'cuando', 'engañó', 'al', 'de', 'los', 'jueces'], ['este', 'llamado', 'primer', 'paso', 'ha', 'sido', 'recibido', 'con', 'muchas', 'críticas', 'por', 'parte', 'de', 'quienes', 'argumentan', 'que', 'no', 'hubo', 'suficientes', 'jueces', 'que', 'otras', 'máquinas', 'se', 'han', 'desempeñado', 'mejor', 'en', 'la', 'prueba', 'en', 'el', 'pasado', 'y', 'que', 'la', 'prueba', 'no', 'es', 'válida', 'por', 'solo', 'durar', 'cinco', 'minutos'], ['en', 'google', 'duplex', 'concertó', 'con', 'éxito', 'una', 'cita', 'con', 'un', 'peluquero', 'por', 'teléfono', 'frente', 'a', 'una', 'multitud', 'de'], ['personas'], ['la', 'recepcionista', 'desconocía', 'por', 'completo', 'que', 'no', 'estaban', 'conversando', 'con', 'un', 'humano', 'real'], ['algunos', 'consideran', 'que', 'esto', 'es', 'un', 'pase', 'de', 'prueba', 'de', 'turing', 'moderno', 'a', 'pesar', 'de', 'no', 'depender', 'del', 'verdadero', 'formato', 'de', 'la', 'prueba', 'tal', 'como', 'lo', 'diseñó', 'alan', 'turing'], ['algunos', 'creen', 'que', 'un', 'modelo', 'de', 'procesamiento', 'de', 'lenguaje', 'natural', 'creado', 'por', 'openai', 'tiene', 'la', 'mejor', 'oportunidad', 'de', 'superar', 'la', 'prueba', 'en', 'su', 'forma', 'real', 'de', 'cualquier', 'tecnología', 'que', 'tengamos', 'hoy'], ['pero', 'incluso', 'con', 'sus', 'capacidades', 'avanzadas', 'de', 'generación', 'de', 'texto', 'muchos', 'han', 'criticado', 'a', 'la', 'máquina', 'porque', 'puede', 'ser', 'engañada', 'para', 'responder', 'preguntas', 'sin', 'sentido', 'y', 'por', 'lo', 'tanto', 'tendría', 'dificultades', 'en', 'las', 'condiciones', 'de', 'la', 'prueba', 'de', 'turing'], ['a', 'pesar', 'de', 'mucho', 'debate', 'sobre', 'la', 'relevancia', 'de', 'la', 'prueba', 'de', 'turing', 'en', 'la', 'actualidad', 'y', 'la', 'validez', 'de', 'las', 'competencias', 'que', 'se', 'basan', 'en', 'ella', 'la', 'prueba', 'sigue', 'siendo', 'un', 'punto', 'de', 'partida', 'filosófico', 'para', 'discutir', 'e', 'investigar', 'la', 'ia'], ['a', 'medida', 'que', 'continuamos', 'avanzando', 'en', 'ia', 'y', 'comprendemos', 'y', 'mapeamos', 'mejor', 'cómo', 'funciona', 'el', 'cerebro', 'humano', 'la', 'prueba', 'de', 'turing', 'sigue', 'siendo', 'fundamental', 'para', 'definir', 'la', 'inteligencia', 'y', 'es', 'una', 'línea', 'de', 'base', 'para', 'el', 'debate', 'sobre', 'lo', 'que', 'debemos', 'esperar', 'de', 'las', 'tecnologías', 'para', 'que', 'se', 'consideren', 'máquinas', 'pensantes']]\n"
     ]
    }
   ],
   "source": [
    "#limpieza\n",
    "oraciones_limpias = []\n",
    "for oracion in oraciones:\n",
    "    #eliminar puntuaciones y dividir por espacios\n",
    "    tokens = oracion.translate(str.maketrans('','',string.punctuation)).split()\n",
    "\n",
    "    #convertir a minusculas\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    \n",
    "    #añadir solo si hay tokens\n",
    "    if tokens:\n",
    "        oraciones_limpias.append(tokens)\n",
    "print(oraciones_limpias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d62a2",
   "metadata": {},
   "source": [
    "**Entrenamiento del modelo Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "974c4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Explicación:\n",
    "- Sentences = las oraciones que usará el modelo para su entrenamiento.\n",
    "- vector_size = Es el tamaño que tendrá nuestro embedding.\n",
    "- window = Desde cuantas palabras debe tomar el modelo para el contexto\n",
    "    (Ejemplo: digamos que tengamos el siguiente texto:\n",
    "    \n",
    "    'Word2Vec es un modelo que **se** utiliza para aprender representaciones vectoriales de palabras.'\n",
    "\n",
    "    (tomaremos \"se\" como nuestra palabra de ejemplo)\n",
    "    Como tenemos window como 5 entonces el modelo tomará 5 palabras antes y 5 palabras despues de dicha palabra para su \n",
    "    contexto.\n",
    "    )\n",
    "- min_count = Cantidad de veces que una palabra debe de repetirse para que el modelo lo tome en consideración.\n",
    "- workers = Cuantos nucleos trabajen a la vez. Cómo mi PC tiene solamente 4 nulceos, solo le pondré 2.\n",
    "'''\n",
    "model = Word2Vec(sentences=oraciones_limpias, vector_size=500, window=5, min_count=1, workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae20c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.47347028e-04,  7.34421075e-04,  5.45657473e-04,  1.91097148e-03,\n",
       "       -1.14477566e-03, -3.88550980e-04,  1.24524871e-03,  1.09907787e-03,\n",
       "        9.28723894e-04,  8.55854596e-04, -3.67195986e-04, -1.62049395e-03,\n",
       "        5.01945557e-04, -1.70184870e-03, -4.58142080e-04, -2.31103203e-03,\n",
       "       -4.60552721e-04, -1.87706784e-03,  1.52443908e-03, -1.27014157e-03,\n",
       "        1.88689632e-03, -1.89683132e-03, -7.14212249e-04,  3.46937595e-04,\n",
       "       -5.28029283e-04,  6.33848540e-04, -6.91117719e-04, -1.53035769e-04,\n",
       "       -1.66848605e-03, -1.93739461e-03,  1.38424593e-03,  5.76823732e-05,\n",
       "        1.18388620e-03, -1.57131720e-03,  7.81230396e-04, -1.77706406e-03,\n",
       "        1.70443300e-03,  9.19384824e-04, -1.36976142e-03,  1.15356455e-03,\n",
       "       -1.24572252e-03, -1.81998056e-03, -2.25714830e-04,  6.78850280e-04,\n",
       "       -1.87789148e-03, -2.14835489e-03,  1.49592140e-03,  4.12870897e-04,\n",
       "        9.04821500e-05,  5.17976121e-04, -8.27674288e-04,  3.37997713e-04,\n",
       "        2.34824329e-04,  1.37092557e-03, -9.34693613e-04,  2.62570276e-04,\n",
       "        1.48057134e-03, -1.42029359e-03, -1.93766691e-03,  1.61081355e-03,\n",
       "        1.79171702e-03, -7.53237749e-04,  1.18806819e-03,  1.97242189e-04,\n",
       "       -1.18531939e-03,  1.41162018e-04, -1.18778786e-03,  1.30067242e-03,\n",
       "        5.39711036e-04, -1.55601010e-03, -2.32095015e-04, -5.65790222e-04,\n",
       "        1.32556132e-03, -2.89733667e-04,  2.03322154e-03,  8.61382927e-04,\n",
       "       -8.37491825e-04,  1.68031675e-03,  7.59694725e-04, -6.67564222e-04,\n",
       "       -1.30365265e-03, -5.36145351e-04, -1.28007564e-03,  1.01083168e-03,\n",
       "       -2.36022752e-03, -8.42220965e-04,  7.39996904e-04,  2.85879767e-04,\n",
       "        1.51483959e-03, -3.92537884e-04, -3.40326878e-05,  6.90556946e-04,\n",
       "        9.05398105e-04,  4.97809378e-04,  2.06668722e-03,  7.40258547e-04,\n",
       "       -1.29371614e-03, -2.37565022e-04, -1.70145335e-03, -9.77989403e-04,\n",
       "       -7.51646468e-04, -1.91749120e-03,  1.90201541e-03,  5.53822669e-04,\n",
       "       -1.99471790e-04, -1.03436178e-03, -1.81897928e-03, -1.72927033e-03,\n",
       "        1.62567850e-03, -3.09599622e-04,  8.62676126e-04, -1.17276818e-03,\n",
       "        2.06438033e-03,  1.02415925e-03,  3.36127341e-05, -7.18025782e-04,\n",
       "        3.83265549e-04, -9.89832566e-04,  1.59149943e-03,  7.23140663e-04,\n",
       "        9.10692397e-05,  7.77465932e-04,  1.01995748e-03, -1.43350521e-03,\n",
       "        2.02999543e-03,  3.21365573e-04, -1.72810641e-03,  1.81978708e-03,\n",
       "       -3.36708588e-04,  1.80532713e-03,  2.57259835e-05,  1.63445016e-03,\n",
       "        5.35622996e-04, -1.14794285e-03, -6.95774390e-04,  2.19488400e-03,\n",
       "        4.36965260e-04, -1.36230281e-03, -1.14502771e-04, -1.02287799e-03,\n",
       "        5.23833674e-04, -1.78386539e-03,  1.48249103e-03,  1.16125229e-04,\n",
       "        1.74672564e-03,  9.21885250e-04, -6.73475384e-04,  5.48946671e-04,\n",
       "        1.10276065e-04, -1.67244487e-03,  1.81221112e-03,  1.91438093e-03,\n",
       "        2.03428557e-03, -4.38546413e-04, -2.28240434e-03,  9.34863929e-04,\n",
       "       -1.27540901e-03,  1.39649480e-03,  2.08382800e-04,  1.17113523e-03,\n",
       "        1.14235771e-03,  2.46860436e-04, -8.39103013e-04, -4.56416237e-05,\n",
       "        1.92415959e-03, -1.30949740e-03,  2.19509166e-04, -3.07787879e-04,\n",
       "        1.08108751e-03,  1.53964525e-03, -6.12402684e-04,  1.13325368e-03,\n",
       "       -9.92718618e-04,  1.08520000e-03,  1.62408769e-03,  3.06963135e-04,\n",
       "       -8.32464022e-04, -6.06429589e-04,  1.42041512e-03,  2.31723464e-03,\n",
       "        9.28597350e-04, -5.76067192e-04, -2.60871864e-04, -1.08948175e-03,\n",
       "       -1.06513035e-03,  7.65250181e-04, -1.64306886e-03, -1.23860245e-03,\n",
       "        1.44657027e-03,  2.13028002e-03,  2.11358955e-03,  1.05982661e-04,\n",
       "       -1.67981151e-03, -1.70884025e-03,  3.51940660e-04, -1.84514432e-03,\n",
       "       -1.71067927e-03,  1.70625572e-04, -4.07506217e-04, -1.73726666e-03,\n",
       "        1.19376054e-03, -1.74929574e-03, -1.04342808e-03, -5.91162243e-04,\n",
       "        5.43227186e-04, -2.78069318e-04, -8.51506076e-04,  1.21215836e-03,\n",
       "        1.30500272e-03, -1.44755479e-03,  1.96579308e-03,  1.06143637e-03,\n",
       "       -1.65876292e-03, -5.36593085e-04,  9.32655588e-04,  9.24922293e-04,\n",
       "       -9.47236666e-04, -1.55813701e-03,  7.33075780e-04, -2.04670755e-03,\n",
       "       -1.17368519e-03,  1.44278074e-05,  1.28462957e-03, -1.15220726e-03,\n",
       "        1.08538184e-03, -8.18945846e-05,  7.93417392e-04,  1.09051517e-03,\n",
       "        2.00459574e-04,  1.35798962e-03,  2.43411196e-04, -1.80461013e-03,\n",
       "        1.75221125e-03, -1.11261348e-03,  8.36895313e-04, -8.48108495e-04,\n",
       "       -1.52710895e-03, -1.76013773e-03,  1.22201908e-03, -2.28035686e-04,\n",
       "        1.84592544e-04, -2.01144372e-03, -1.46368193e-03, -8.61357490e-04,\n",
       "        1.63384143e-03, -1.91575009e-03,  1.00028166e-03, -1.44808568e-04,\n",
       "        3.05316382e-04,  1.92839780e-03, -7.40815129e-04, -1.96230086e-03,\n",
       "        2.49673933e-04,  1.41523231e-03,  1.78264920e-03, -4.86061530e-04,\n",
       "        6.24975713e-04,  1.34445098e-03, -1.44798378e-03,  1.51250220e-03,\n",
       "       -1.52390858e-03,  5.58242609e-04,  5.27883472e-04,  9.46821528e-04,\n",
       "       -7.61590549e-04,  6.22477150e-04,  1.24257361e-03,  2.14569690e-03,\n",
       "       -2.19712988e-03,  9.05400142e-04,  7.38756265e-04,  3.69714398e-05,\n",
       "        2.35530338e-03, -1.05808594e-03, -4.78766568e-04, -1.42640935e-03,\n",
       "       -8.45775940e-04, -2.93310179e-04, -7.82798452e-04, -7.63274031e-04,\n",
       "        1.33265438e-03, -1.07031094e-03, -1.54330861e-03,  1.19474891e-03,\n",
       "        2.45019863e-03,  4.98245819e-04,  8.24782910e-06,  3.19711035e-05,\n",
       "        1.23598817e-04,  1.24905480e-03, -1.32163276e-03,  6.86339859e-04,\n",
       "        9.21227620e-04, -3.57728393e-04,  5.39176574e-04,  9.24874679e-04,\n",
       "        2.39067338e-03,  1.49746877e-04,  1.96518423e-03, -1.41310995e-03,\n",
       "        8.08919838e-04, -6.46237226e-04, -9.78838070e-04,  2.99229956e-04,\n",
       "       -6.08973787e-04, -1.44244428e-03,  6.59422367e-04,  1.85326824e-03,\n",
       "       -1.30992383e-03, -1.97992730e-03, -7.95958040e-04,  1.10313320e-03,\n",
       "       -1.74799038e-03,  2.25596479e-03,  5.64144138e-05,  5.47317672e-04,\n",
       "       -2.11448656e-04, -1.28967664e-03,  6.86538697e-04,  1.19078660e-03,\n",
       "       -1.06834120e-03, -2.90200667e-04,  3.84641258e-04,  5.18845103e-04,\n",
       "        1.22100476e-03, -7.43519340e-04,  1.48141792e-03, -1.47375511e-03,\n",
       "       -2.16902350e-04,  1.73318491e-03,  1.48373190e-03, -1.71606313e-03,\n",
       "       -8.72510354e-05, -1.74071616e-03, -3.40102910e-04,  9.74802417e-04,\n",
       "       -1.35607540e-03,  1.46831537e-03,  9.85205523e-04, -1.19826163e-03,\n",
       "       -2.12363433e-03, -5.59214968e-04, -1.17552074e-04,  3.86983826e-04,\n",
       "        1.86679047e-03,  3.54634307e-04, -1.04317430e-03,  5.89730800e-04,\n",
       "       -1.32715737e-03, -3.16764017e-05, -2.49408738e-04,  2.03861971e-03,\n",
       "       -1.41980196e-03, -1.17547123e-03,  2.02626747e-04,  1.09437085e-03,\n",
       "       -1.66470394e-03, -1.24197733e-03, -2.75479222e-04, -6.97018870e-04,\n",
       "       -1.81360124e-03, -6.44636224e-04, -4.74220258e-04,  1.54136773e-03,\n",
       "       -6.25233661e-05,  2.39097280e-04,  1.57679999e-04, -7.12344190e-04,\n",
       "        3.12451477e-04,  3.58288438e-04,  1.43712270e-03, -3.44884262e-04,\n",
       "       -1.81146048e-03,  1.39127776e-04,  1.77068426e-03, -1.28393050e-03,\n",
       "       -1.15005998e-03, -4.29156498e-04,  1.63096457e-03, -2.81660818e-04,\n",
       "        2.00984511e-03, -1.69949280e-03,  2.19418155e-03, -1.75549125e-03,\n",
       "        1.81331357e-03,  2.73864833e-04,  6.83257997e-04, -9.28958412e-04,\n",
       "        1.80897897e-03,  1.12510612e-03, -1.11918419e-03, -2.08519748e-03,\n",
       "        1.40047481e-03, -1.06983923e-03, -1.52401591e-03,  9.16239864e-04,\n",
       "       -9.30166338e-04, -1.61194371e-03,  1.95347937e-03,  8.44808819e-05,\n",
       "       -7.68428668e-04, -6.34119962e-04, -1.19967409e-03, -1.31979981e-03,\n",
       "       -1.41115685e-03, -1.31499802e-03, -1.61575491e-03,  2.07938813e-03,\n",
       "        1.25421176e-03, -8.60451895e-04,  4.48521896e-04, -1.84565794e-03,\n",
       "        1.43614528e-03,  1.48004037e-03,  2.28489836e-04, -1.10931671e-03,\n",
       "       -3.98936972e-04,  7.96248205e-04, -6.07415452e-04,  3.06390953e-04,\n",
       "        1.74375798e-03,  9.87646054e-04, -1.20446284e-03,  1.19028112e-03,\n",
       "       -7.55792600e-04, -1.17181521e-03,  1.22668047e-03, -2.01483048e-03,\n",
       "       -5.21346170e-04, -3.95707757e-04, -1.97198708e-03, -2.38778412e-05,\n",
       "        1.01697689e-03, -9.98921460e-04, -1.51696161e-03,  1.42266310e-03,\n",
       "       -6.48237998e-04, -1.71451690e-03, -5.02795265e-05,  1.88400707e-04,\n",
       "        1.48861017e-03,  8.08287659e-05,  1.77487312e-03, -2.05833139e-03,\n",
       "        1.51657022e-03,  1.26037456e-03,  5.84076100e-04, -3.91150301e-04,\n",
       "        1.06196145e-04, -2.90569675e-04, -1.53030257e-03, -1.29025301e-03,\n",
       "        1.60478085e-04, -8.72739532e-04,  2.05404731e-03, -4.21130098e-04,\n",
       "        1.16620003e-03,  2.31357699e-04,  1.72945356e-03, -1.88475009e-03,\n",
       "        6.83634367e-04, -1.67112172e-04,  4.53580316e-04,  1.05601765e-04,\n",
       "       -1.66795671e-03,  1.73208222e-03, -7.24678626e-04, -1.20223449e-04,\n",
       "       -1.49198482e-03,  1.11400511e-03,  1.75283814e-03, -2.96314160e-04,\n",
       "        1.48091151e-03, -4.70502768e-04,  1.94957352e-03,  2.38367566e-03,\n",
       "        2.25675220e-04, -3.38319544e-04, -2.16919486e-03,  1.73387292e-03,\n",
       "       -6.63670071e-04, -5.53422287e-05, -6.01059524e-04,  2.25378969e-03,\n",
       "        1.75838917e-03,  4.34997695e-04,  5.65685797e-04,  1.68424845e-03,\n",
       "        6.61383499e-04,  1.25285878e-03,  1.45299127e-04, -5.21975511e-04,\n",
       "        1.39921880e-03, -6.71805290e-04, -1.76211528e-04,  1.79174310e-03,\n",
       "       -1.79563556e-03, -9.40634112e-04, -8.67989846e-04,  1.06449879e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veamos el vector de alguna palabra del texto\n",
    "vector = model.wv['turing']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inteligencia', 0.16513270139694214),\n",
       " ('que', 0.16042950749397278),\n",
       " ('con', 0.14856107532978058),\n",
       " ('inversa', 0.13980995118618011),\n",
       " ('encuestado', 0.1364438235759735),\n",
       " ('una', 0.13562528789043427),\n",
       " ('respuestas', 0.1329558938741684),\n",
       " ('actual', 0.13223935663700104),\n",
       " ('de', 0.13075046241283417),\n",
       " ('fue', 0.12661340832710266)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_cercanas = model.wv.most_similar(\"turing\", topn=10)\n",
    "palabras_cercanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85690207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('operado', 0.17433081567287445),\n",
       " ('personas', 0.16796386241912842),\n",
       " ('turing', 0.16513271629810333),\n",
       " ('paso', 0.14612695574760437),\n",
       " ('lovelace', 0.14592580497264862),\n",
       " ('pasado', 0.13158577680587769),\n",
       " ('mapeamos', 0.13051386177539825),\n",
       " ('mensajes', 0.12683376669883728),\n",
       " ('donde', 0.12481240928173065),\n",
       " ('a', 0.12445157021284103)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_cercanas = model.wv.most_similar(\"inteligencia\", topn=10)\n",
    "palabras_cercanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a92276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código para guardar el modelo\n",
    "model.save(\"modelo_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código para cargar modelo\n",
    "modelo_cargado = Word2Vec.load(\"modelo_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportar Embeddings\n",
    "#si lo queremos como texto\n",
    "model.wv.save_word2vec_format('embedding.txt', binnary=False)\n",
    "#si lo queremos como bin\n",
    "model.wv.save_word2vec_format('embedding.bin', binnary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar algun embedding\n",
    "from gensim.models import KeyedVectors\n",
    "#Si es texto \n",
    "embeddings_cargados = KeyedVectors.load_word2vec_format('embedding.txt', binnary= False)\n",
    "#Si es bin\n",
    "embeddings_cargados = KeyedVectors.load_word2vec_format('embedding.bin', binnary= True)\n",
    "\n",
    "embeddings_cargados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51a778",
   "metadata": {},
   "source": [
    "Digamos que queremos cargar un conjunto de PDF's, entonces haríamos lo siguiente:\n",
    "NOTA: En este caso solo se colocará el código que se puede usar ya que para estos ejemplos no puedo proporcionar pdf que puedan usar de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalamos la siguiente libreria solo para la ayuda visual\n",
    "%pip install tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importación de librerias\n",
    "import os\n",
    "import pymupdf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(ruta_archivo):\n",
    "    doc = pymupdf.open(ruta_archivo)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_carpeta = \"\"\n",
    "todos_los_textos = []\n",
    "\n",
    "for archivo in tqdm(os.listdir(ruta_carpeta)):\n",
    "    if archivo.endswith('.pdf'):\n",
    "        ruta_completa = os.path.join(ruta_carpeta, archivo)\n",
    "        try:\n",
    "            documento = extraer_texto_pdf(ruta_completa)\n",
    "            todos_los_textos.append(documento)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {archivo}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6415a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oraciones_totales = []\n",
    "long = 0\n",
    "\n",
    "for documento in todos_los_textos:\n",
    "    long = long + len(documento)\n",
    "    oraciones = documento.split('.') # o ','\n",
    "    oraciones_totales.extend(oraciones)\n",
    "\n",
    "print(f\"Número de caracteres: {long}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7164e",
   "metadata": {},
   "source": [
    "Ya apartir de este punto solo vuelven a hacer limpieza, entrenamiento y testean con palabras como se vio en puntos anteriores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
